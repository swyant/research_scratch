{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mace-torch[wandb]\n",
    "!pip install cuequivariance cuequivariance-torch cuequivariance-ops-torch-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/colab_temp/mace_fine-tuning_expts/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"drive/MyDrive/colab_temp/mace_fine-tuning_expts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import mace.tools.scripts_utils as scripts_utils\n",
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "from mace import tools\n",
    "from mace.data import KeySpecification\n",
    "\n",
    "def patched_setup_wandb(args: argparse.Namespace):\n",
    "    logging.info(\"Using Weights and Biases for logging\")\n",
    "    import wandb\n",
    "\n",
    "    wandb_config = {}\n",
    "    args_dict = vars(args)\n",
    "\n",
    "    for key, value in args_dict.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            args_dict[key] = value.tolist()\n",
    "\n",
    "    class CustomEncoder(json.JSONEncoder):\n",
    "        def default(self, o):\n",
    "            if isinstance(o, KeySpecification):\n",
    "                return o.__dict__\n",
    "            return super().default(o)\n",
    "\n",
    "    clean_dict = {}\n",
    "    for k,v in args_dict.items():\n",
    "        if k == 'compute_atomic_dipole':\n",
    "            print(\"found the bad one\")\n",
    "            continue\n",
    "        clean_dict[k] = v\n",
    "\n",
    "    args_dict_json = json.dumps(clean_dict, cls=CustomEncoder)\n",
    "    for key in args.wandb_log_hypers:\n",
    "        wandb_config[key] = args_dict[key]\n",
    "    tools.init_wandb(\n",
    "        project=args.wandb_project,\n",
    "        entity=args.wandb_entity,\n",
    "        name=args.wandb_name,\n",
    "        config=wandb_config,\n",
    "        directory=args.wandb_dir,\n",
    "    )\n",
    "    wandb.run.summary[\"params\"] = args_dict_json\n",
    "\n",
    "scripts_utils.setup_wandb = patched_setup_wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile configs/dpp_small_ft-HfOx_v0.9.yml\n",
    "\n",
    "model: 'MACE'\n",
    "foundation_model: 'small'\n",
    "multiheads_finetuning: False\n",
    "train_file: 'data/dpp_train.xyz'\n",
    "valid_file: 'data/dpp_validation.xyz'\n",
    "test_file: 'data/test.xyz'\n",
    "energy_key: \"REF_energy\"\n",
    "forces_key: \"REF_forces\"\n",
    "E0s: {8: -443.8224565134432, 72: -1529.4984727695407}\n",
    "name: \"small_ft-HfOx\"\n",
    "model_dir: \"models/small_dpp_HfOx-ft_8\"\n",
    "log_dir: \"models/small_dpp_HfOx-ft_8\"\n",
    "results_dir: \"models/small_dpp_HfOx-ft_8\"\n",
    "checkpoints_dir: \"models/small_dpp_HfOx-ft_8\"\n",
    "device: cuda\n",
    "batch_size: 14\n",
    "max_num_epochs: 500\n",
    "lr: 0.01\n",
    "ema: True\n",
    "ema_decay: 0.99\n",
    "optimizer: adam\n",
    "weight_decay: 5e-4\n",
    "swa: True\n",
    "seed: 123\n",
    "stress_weight: 0.0\n",
    "forces_weight: 100.0\n",
    "energy_weight: 1.0\n",
    "#scheduler_patience: 20\n",
    "#lr_factor: 0.2\n",
    "huber_delta: 0.001\n",
    "scheduler: ExponentialLR\n",
    "wandb: True\n",
    "enable_cueq: True\n",
    "wandb_project: \"MACE_HfOx_from-scratch\"\n",
    "wandb_name: \"HfOx_1\"\n",
    "wandb_log_hypers: [\"lr\", \"lr_factor\", \"lr_scheduler_gamma\", \"scheduler\",\n",
    "                   \"swa\", \"swa_lr\", \"start_swa\", \"scheduler_patience\",\n",
    "                   \"swa_energy_weight\", \"swa_forces_weight\",\n",
    "                   \"energy_weight\", \"forces_weight\",\n",
    "                   \"ema\", \"ema_decay\", \"weight_decay\",\n",
    "                   \"huber_delta\", \"optimizer\", \"amsgrad\", \"beta\",\n",
    "                   \"batch_size\", \"max_num_epochs\", \"seed\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from mace.cli.run_train import main as mace_run_train_main\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "def train_mace(config_file_path):\n",
    "    logging.getLogger().handlers.clear()\n",
    "    sys.argv = [\"program\", \"--config\", config_file_path, \"--plot\", \"true\", \"--plot_frequency\", \"10\"]\n",
    "    mace_run_train_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mace(\"configs/dpp_small_ft-HfOx_v0.9.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from mace.cli.plot_train import main as mace_plot_train_main\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "def train_mace(config_file_path):\n",
    "    logging.getLogger().handlers.clear()\n",
    "    sys.argv = [\"program\", \"--config\", config_file_path]\n",
    "    mace_run_train_main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
