{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using PotentialLearning, InteratomicPotentials\n",
    "using Unitful\n",
    "using Random\n",
    "using AtomsBase\n",
    "using DelimitedFiles\n",
    "using Statistics: mean\n",
    "using StatsBase\n",
    "using Clustering, Distances\n",
    "using Trapz\n",
    "\n",
    "using CairoMakie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace = ACE(#species           = [:C,:H,:O,:N,:F],\n",
    "          species           = [:C,:H,:O,:N],\n",
    "          #body_order        = 4,\n",
    "          body_order        = 3,\n",
    "          #polynomial_degree = 16,\n",
    "          polynomial_degree = 10,\n",
    "          wL                = 2.0,\n",
    "          csp               = 1.0,\n",
    "          r0                = 1.43,\n",
    "          rcutoff           = 4.4 )\n",
    "length(ace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_file = \"../files/QM9/qm9_fullset_alldata.xyz\"\n",
    "raw_data = load_data(qm9_file, ExtXYZ(u\"eV\", u\"Å\"))\n",
    "raw_data = [config for config in raw_data if !(:F in atomic_symbol(get_system(config)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing structures with Fluorine results in 1,1923 fewer configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = DataSet([config for config in raw_data if !(:F in atomic_symbol(get_system(config)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_perm_idxs = Random.randperm(Xoshiro(1), length(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_train = 120_001\n",
    "possible_training_idxs = master_perm_idxs[1:max_num_train]\n",
    "possible_test_idxs = master_perm_idxs[max_num_train+1:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_train = 120_000\n",
    "num_train = 40_000\n",
    "train_idxs = possible_training_idxs[1:num_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[train_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only fitted this once, then I skip the `ooc_learn_eonly!` routine in future runs of this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LBasisPotential(ace)\n",
    "#_AtWA, _AtWb = PotentialLearning.ooc_learn_eonly!(lb, raw_data[train_idxs];symmetrize=false, λ=0.01, pbar=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open(\"qm9_4elem_3body_poly10_fit40K.txt\", \"w\") do io\n",
    "#    writedlm(io, lb.β)\n",
    "#end\n",
    "\n",
    "lb.β .= readdlm(\"qm9_4elem_3body_poly10_fit40K.txt\", Float64)\n",
    "#open(\"qm9_4elem_3body_poly10_fit40K.txt\", \"r\") do io\n",
    "#    readdlm(io, lb.β)\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etest_ref = get_all_energies(raw_data[possible_test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etest_local_descrs = compute_local_descriptors(raw_data[possible_test_idxs],lb.basis)\n",
    "ds_test = DataSet(raw_data[possible_test_idxs] .+ etest_local_descrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etest_pred = get_all_energies(ds_test,lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@show e_mae, e_rmse, e_rsq = calc_metrics(etest_pred,etest_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e_mae, e_rmse, e_rsq) = calc_metrics(etest_pred, etest_ref) = (0.04422691459021048, 0.06343019540788734, 0.9999609908582189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sys = get_system(raw_data[train_idxs[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(InteratomicPotentials.compute_local_descriptors(test_sys, lb.basis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about computing the distance vector: \n",
    "- feature vector for each config is averaged over atoms (not summed)\n",
    "- feature vector is standardized when generating the k-means cluster\n",
    "- does appear to be using Euclidean distance with k-means (they pass \"Minkowski\", which seems to default to p=2)\n",
    "- when getting the final distance metric, they take the average distance between all cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_feature_perconfig = Vector{Float64}[]\n",
    "for (i,config) in enumerate(raw_data[train_idxs])\n",
    "    if i % 100 == 0\n",
    "        println(i)\n",
    "    end\n",
    "    mean_feature = mean(InteratomicPotentials.compute_local_descriptors(get_system(config), lb.basis))\n",
    "    push!(mean_feature_perconfig,mean_feature)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_features = reduce(hcat,mean_feature_perconfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = StatsBase.fit(ZScoreTransform, mean_train_features, dims=2)\n",
    "std_mean_train_features = StatsBase.transform(dt,mean_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = 10\n",
    "km = kmeans(std_mean_train_features, num_neighbors, distance=Distances.Euclidean(), rng=Xoshiro(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_feature_perconfig = Vector{Float64}[]\n",
    "for (i,config) in enumerate(raw_data[possible_test_idxs])\n",
    "    if i % 100 == 0\n",
    "        println(i)\n",
    "    end\n",
    "    mean_feature = mean(InteratomicPotentials.compute_local_descriptors(get_system(config), lb.basis))\n",
    "    push!(mean_test_feature_perconfig,mean_feature)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_features = reduce(hcat, mean_test_feature_perconfig)\n",
    "std_mean_test_features = StatsBase.transform(dt,mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_test_vec = std_mean_test_features[:,1]\n",
    "mean(mapslices(x->Distances.euclidean(example_test_vec,x), km.centers, dims=1))\n",
    "#Distances.euclidean(example_test_vec,km.centers[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function my_distance(test_vec)\n",
    "    dist = mean(mapslices(x->Distances.euclidean(test_vec,x), km.centers, dims=1))\n",
    "    #dist = minimum(mapslices(x->Distances.euclidean(test_vec,x), km.centers, dims=1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_distances = mapslices(my_distance, std_mean_test_features, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_calib = 0.1\n",
    "num_calib = floor(Int64, fraction_calib*length(possible_test_idxs))\n",
    "num_test = length(possible_test_idxs) - num_calib\n",
    "\n",
    "calib_idxs = possible_test_idxs[1:num_calib] # this is useless, etest and test_feature_distances already indexed from raw\n",
    "test_idxs  = possible_test_idxs[num_calib+1:end] # this is useless\n",
    "\n",
    "#actually I do need those idxs sets (that index the raw_data)\n",
    "calib_num_atoms = length.(get_system.(raw_data[calib_idxs]))\n",
    "test_num_atoms = length.(get_system.(raw_data[test_idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_test_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the Medford paper takes as a quantity of interest as the energy normalized by the number of atoms, rather than the raw energy. I suspect that it doesn't make that much of a difference for this dataset since the number of atoms are pretty similar, but for very big differences I'm sure it probably starts to matter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_scores = abs.(etest_pred[1:num_calib] .- etest_ref[1:num_calib]) ./ test_feature_distances[1:num_calib]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "q_hat = quantile(calib_scores, ceil((num_calib+1)*(1-alpha))/num_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_abs_residuals = abs.(etest_pred[num_calib+1:end] .- etest_ref[num_calib+1:end])\n",
    "qhat_scores = q_hat*test_feature_distances[num_calib+1:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_abs_residuals .> qhat_scores) / num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(test_feature_distances[num_calib+1:end],bins=100)\n",
    "# I'm not sure, quantitatively, what constitutes being sufficiently adaptive.\n",
    "# Ultimately it seems dependent on the dataset in addition to the score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_complements = collect(range(0.01,0.99,step=0.01))\n",
    "alpha_refs = 1 .- alpha_complements\n",
    "\n",
    "predicted_alphas = Float64[]\n",
    "for ac in alpha_complements\n",
    "    alpha = 1-ac\n",
    "    qh = quantile(calib_scores, clamp(ceil((num_calib+1)*(1-alpha))/num_calib, 0.0, 1.0))\n",
    "\n",
    "    qh_scores = qh*test_feature_distances[num_calib+1:end]\n",
    "    predicted_alpha = sum(test_abs_residuals .> qh_scores) / num_test\n",
    "    push!(predicted_alphas, predicted_alpha)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_calibration_plot(expected_ps, observed_ps; width=600)\n",
    "    # Convert to percentages\n",
    "    expected_ps = expected_ps .* 100\n",
    "    observed_ps = observed_ps .* 100\n",
    "\n",
    "    fig = Figure(resolution=(width, width))\n",
    "    ax = Axis(fig[1, 1],\n",
    "        aspect=DataAspect(),\n",
    "        xlabel=\"Expected conf. level\",\n",
    "        ylabel=\"Observed conf. level\",\n",
    "        limits=(0, 100, 0, 100)\n",
    "    )\n",
    "\n",
    "    # Main line\n",
    "    lines!(ax, expected_ps, observed_ps)\n",
    "\n",
    "    # Diagonal reference line\n",
    "    lines!(ax, expected_ps, expected_ps, linestyle=:dash, alpha=0.4)\n",
    "\n",
    "    # Filled area between curves\n",
    "    band!(ax, expected_ps, expected_ps, observed_ps, color=(:blue, 0.2))\n",
    "\n",
    "    # Configure ticks - approximately 4 ticks on each axis\n",
    "    ax.xticks = 0:10:100\n",
    "    ax.yticks = 0:10:100\n",
    "\n",
    "    # Add percentage signs to ticks\n",
    "    ax.xtickformat = xs -> [\"$(Int(x))%\" for x in xs]\n",
    "    ax.ytickformat = xs -> [\"$(Int(x))%\" for x in xs]\n",
    "\n",
    "    ## Add text for miscalibration area\n",
    "    #text!(ax, \"miscalc. area = $(round(area, digits=3))\",\n",
    "    #    position=(8, 2),\n",
    "    #    align=(:left, :bottom)\n",
    "    #)\n",
    "\n",
    "    return fig\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_miscalibration_area(expected_ps, observed_ps)\n",
    "    area = 0.0\n",
    "    for i in 2:length(expected_ps)-1\n",
    "        trap = abs(trapz(expected_ps[i-1:i+1], observed_ps[i-1:i+1]) -\n",
    "                 trapz(expected_ps[i-1:i+1], expected_ps[i-1:i+1]))\n",
    "        area += trap\n",
    "    end\n",
    "    area\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_miscalibration_area(alpha_refs, predicted_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_calibration_plot(alpha_refs,predicted_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
