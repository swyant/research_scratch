{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt here was hierarchical clustering, but didn't realize the whole distance matrix was needed. Without using an out-of-core method, this is entirely infeasible, so I switched to DBscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using PotentialLearning, InteratomicPotentials\n",
    "using Unitful\n",
    "using Random\n",
    "using AtomsBase\n",
    "using DelimitedFiles\n",
    "using Statistics: mean, var\n",
    "using StatsBase\n",
    "using Clustering, Distances, NearestNeighbors\n",
    "using Trapz\n",
    "using LinearAlgebra: Symmetric, eigen, mul!, svd, cond, dot, norm\n",
    "\n",
    "using MultivariateStats, StatsAPI\n",
    "\n",
    "using JLD2\n",
    "\n",
    "#using CairoMakie CairoMakie.activate!()\n",
    "using GLMakie; GLMakie.activate!(inline=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup basis, read in and organize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace = ACE(species           = [:C,:H,:O,:N],\n",
    "          body_order        = 3,\n",
    "          polynomial_degree = 10,\n",
    "          wL                = 2.0,\n",
    "          csp               = 1.0,\n",
    "          r0                = 1.43,\n",
    "          rcutoff           = 4.4 )\n",
    "lb = LBasisPotential(ace)\n",
    "length(ace)\n",
    "\n",
    "qm9_file = \"../files/QM9/qm9_fullset_alldata.xyz\"\n",
    "raw_data = load_data(qm9_file, ExtXYZ(u\"eV\", u\"Å\"))\n",
    "raw_data = DataSet([config for config in raw_data if !(:F in atomic_symbol(get_system(config)))])\n",
    "\n",
    "max_num_train = 120_001\n",
    "master_perm_idxs = readdlm(\"./primary_permutation.txt\", Int64)\n",
    "possible_training_idxs = master_perm_idxs[1:max_num_train]\n",
    "possible_test_idxs = master_perm_idxs[max_num_train+1:end]\n",
    "\n",
    "num_train = 40_000\n",
    "train_idxs = possible_training_idxs[1:num_train]\n",
    "\n",
    "lb.β .= readdlm(\"qm9_4elem_3body_poly10_fit40K.txt\", Float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute test descriptors and metrics (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etest_ref = get_all_energies(raw_data[possible_test_idxs])\n",
    "\n",
    "etest_local_descrs = compute_local_descriptors(raw_data[possible_test_idxs],lb.basis)\n",
    "ds_test = DataSet(raw_data[possible_test_idxs] .+ etest_local_descrs)\n",
    "etest_pred = get_all_energies(ds_test,lb)\n",
    "\n",
    "num_atoms_test = length.(get_system.(raw_data[possible_test_idxs]))\n",
    "\n",
    "@show e_mae, e_rmse, e_rsq = calc_metrics(etest_pred./num_atoms_test,etest_ref./num_atoms_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_mean_features(ds)\n",
    "    mean_feature_perconfig = Vector{Float64}[]\n",
    "    for (i,config) in enumerate(ds)\n",
    "        if i % 100 == 0\n",
    "            println(i)\n",
    "        end\n",
    "        mean_feature = mean(InteratomicPotentials.compute_local_descriptors(get_system(config), lb.basis))\n",
    "        push!(mean_feature_perconfig,mean_feature)\n",
    "    end\n",
    "\n",
    "    reduce(hcat,mean_feature_perconfig)\n",
    "end\n",
    "\n",
    "function normdists2centers(feature_vec, km)\n",
    "    dists = mapslices(x->Distances.euclidean(feature_vec,x), km.centers, dims=1)\n",
    "    normed_dists = dists ./ sum(dists)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_features = compute_mean_features(raw_data[train_idxs])\n",
    "mean_test_features  = compute_mean_features(raw_data[possible_test_idxs])\n",
    "\n",
    "dt = StatsBase.fit(ZScoreTransform, mean_train_features, dims=2)\n",
    "std_mean_train_features = StatsBase.transform(dt,mean_train_features)\n",
    "std_mean_test_features = StatsBase.transform(dt,mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"ace_qm9_train_features.jld2\", Dict(\"std_mean_train_features\" => std_mean_train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = StatsAPI.fit(MultivariateStats.PCA, std_mean_train_features; mean=0)\n",
    "\n",
    "pca_std_train_features = StatsAPI.predict(M1, std_mean_train_features)\n",
    "pca_std_test_features = StatsAPI.predict(M1, std_mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"ace_qm9_215pca_train_features.jld2\", Dict(\"pca_std_train_features\" => pca_std_train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nope too much data\n",
    "#pca_train_distances = Distances.pairwise(Distances.Euclidean, pca_std_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Msmall = StatsAPI.fit(MultivariateStats.PCA, std_mean_train_features; mean=0,maxoutdim=2)\n",
    "\n",
    "small_pca_std_train_features = StatsAPI.predict(Msmall, std_mean_train_features)\n",
    "small_pca_std_test_features = StatsAPI.predict(Msmall, std_mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_5  = kmeans(small_pca_std_train_features, 5, distance=Distances.Euclidean(), rng=Xoshiro(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dist2centers_5 = mapslices(x->reshape(normdists2centers(x,km_5),:,1), small_pca_std_train_features; dims=1)\n",
    "small_train_assignments_5 = vec(mapslices(x->argmax(x), small_train_dist2centers_5; dims=1))\n",
    "num_inclusters_5 = [length(findall(==(i), small_train_assignments_5)) for i in 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_cluster = findall(==(1),small_train_assignments_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_indices = StatsBase.sample(first_cluster,100)\n",
    "trial_idx = trial_indices[1]\n",
    "\n",
    "dists = Vector{Float64}(undef, length(first_cluster)-1)\n",
    "local_i = 1\n",
    "for idx in first_cluster\n",
    "     if idx == trial_idx\n",
    "        continue\n",
    "     end\n",
    "    dists[local_i] = euclidean(pca_std_train_features[:,trial_idx], pca_std_train_features[:,idx])\n",
    "    local_i += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(dists, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clusters = dbscan(pca_std_train_features, 15.0, min_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist([cluster.size for cluster in my_clusters.clusters], bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([cluster.size for cluster in my_clusters.clusters])/size(pca_std_train_features)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clusters.clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually varied min_neighbors and radius many times, and honestly either I ended up with 1-2 big clusters and most points accounted for, or like 10-20 reasonably balanced groups but most points excluded. Not sure there really is a clean separation in the data. I suspect that if I could compare atom-level features, I'd have more relevant atomic clusters.\n",
    "\n",
    "Also, if there was a way to cluster by both locality and systemic bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_4  = kmeans(small_pca_std_train_features, 4, distance=Distances.Euclidean(), rng=Xoshiro(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK let's go with the 2-dimensional PCA clusters obtained with kmeans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dist2centers_4 = mapslices(x->reshape(normdists2centers(x,km_4),:,1), small_pca_std_train_features; dims=1)\n",
    "small_train_assignments_4 = vec(mapslices(x->argmax(x), small_train_dist2centers_4; dims=1))\n",
    "num_inclusters_4 = [length(findall(==(i), small_train_assignments_4)) for i in 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_cluster_residuals(idxs, raw_ds, lb)\n",
    "    eref = get_all_energies(raw_ds[idxs])\n",
    "\n",
    "    e_lds = compute_local_descriptors(raw_ds[idxs],lb.basis)\n",
    "    ds = DataSet(raw_ds[idxs] .+ e_lds)\n",
    "    epred = get_all_energies(ds,lb)\n",
    "\n",
    "    num_atoms = length.(get_system.(raw_ds[idxs]))\n",
    "\n",
    "    residuals = (epred .- eref) ./ num_atoms\n",
    "    residuals\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_idx = 4\n",
    "check_idxs = findall(==(check_idx), small_train_assignments_4)\n",
    "residuals = compute_cluster_residuals(check_idxs, raw_data, lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000*mean(residuals), 1000*sqrt(var(residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(residuals, bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function plot_pca_clusters(features, clusters; residuals=nothing)\n",
    "    fig = Figure(resolution = (800, 600))\n",
    "    ax = Axis(fig[1, 1],\n",
    "        xlabel = \"PC1\",\n",
    "        ylabel = \"PC2\",\n",
    "        title = \"PCA Scatter Plot\"\n",
    "    )\n",
    "\n",
    "    # Create a color palette for 4 clusters\n",
    "    colors = [:blue, :red, :green, :purple]\n",
    "    clims = (-0.001, 0.001)\n",
    "\n",
    "    if !isnothing(residuals)\n",
    "        # Scatter plot with points colored by cluster\n",
    "        scatter!(ax,\n",
    "            features[1, :], features[2, :],\n",
    "            color = residuals,\n",
    "            colormap= :viridis,\n",
    "            colorrange=clims,\n",
    "            markersize = 3,\n",
    "            alpha = 0.6\n",
    "            )\n",
    "\n",
    "    else\n",
    "        # Scatter plot with points colored by cluster\n",
    "        scatter!(ax,\n",
    "            features[1, :], features[2, :],\n",
    "            #color = [colors[c] for c in clusters],\n",
    "            color= :black,\n",
    "            markersize = 3,\n",
    "            alpha = 0.6\n",
    "            )\n",
    "    end\n",
    "\n",
    "    Colorbar(fig[1, 2],\n",
    "    colormap = :viridis,\n",
    "    limits = clims)\n",
    "\n",
    "    return fig\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_pca_clusters(small_pca_std_train_features, small_train_assignments_4)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_residuals = compute_cluster_residuals(1:40_000, raw_data, lb) # OOOPSS! This should have been train_idxs.\n",
    "all_residuals = compute_cluster_residuals(train_idxs, raw_data, lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_pca_clusters(small_pca_std_train_features, small_train_assignments_4; residuals=all_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(all_residuals; bins=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Danny has pointed out, really I should be plotting more than one set of PCA axes, in one of the diagonal marginal plots. Also it turns out that Danny and Ayoub have explicitly been working on this problem of empty clusters with high-dimensional kmeans clustering. (Also apparently, if you start the kmeans centers, it's provable that you should not have empty clusters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M10 = StatsAPI.fit(MultivariateStats.PCA, std_mean_train_features; mean=0,maxoutdim=10)\n",
    "\n",
    "pca10_std_train_features = StatsAPI.predict(M10, std_mean_train_features)\n",
    "pca10_std_test_features = StatsAPI.predict(M10, std_mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function marginal_plots(samples; N_plots=5, residuals=nothing)\n",
    "    # Assumes dataset `samples` of size (N_dim, N_data)\n",
    "    clims = (-0.001, 0.001)\n",
    "    fig = Figure(size=(500,500))\n",
    "    for i in 1:N_plots\n",
    "        axii = fig[i, i] = Axis(fig, aspect = 1)\n",
    "        hidedecorations!(axii)\n",
    "        hist!(axii, samples[i,:], bins = 50)\n",
    "        for j in i+1:N_plots\n",
    "            ax = fig[i, j] = Axis(fig, aspect = 1)\n",
    "            hidedecorations!(ax)\n",
    "            if isnothing(residuals)\n",
    "                scatter!(ax, samples[[j,i],:], markersize = 2, color = (:black,0.2))\n",
    "            else\n",
    "                scatter!(ax, samples[[j,i],:], markersize = 1, color =residuals, colormap=:viridis, colorrange=clims)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    rowgap!(fig.layout, 0)\n",
    "    colgap!(fig.layout, 0)\n",
    "    fig\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_plots(pca10_std_train_features, N_plots=10, residuals=residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
