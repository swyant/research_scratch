{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdd = np.loadtxt(\"pod.gdd.dat\", skiprows=4)\n",
    "ldd = np.loadtxt(\"pod.ldd.dat\", skiprows=4)\n",
    "\n",
    "ld_atom = np.loadtxt(\"dump_ld\", skiprows=9)\n",
    "dd_atom = np.loadtxt(\"dump_dd\", skiprows=9)\n",
    "\n",
    "coeffs = np.loadtxt(\"../HfO2_FPOD_020224_v2_coefficients.pod\", skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bin_file(fname):\n",
    "    numbers = []\n",
    "    with open(fname, mode=\"rb\") as f:\n",
    "        while (byte := f.read(8)):\n",
    "            (number, ) = struct.unpack('d',byte) \n",
    "            numbers.append(number)\n",
    "    return numbers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_gd = parse_bin_file(\"../fitpod_ref/train/globaldescriptors_config1.bin\")\n",
    "fit_ld = parse_bin_file(\"../fitpod_ref/train/basedescriptors_config1.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(gdd))\n",
    "print(np.shape(ldd))\n",
    "print(np.shape(ld_atom))\n",
    "print(np.shape(dd_atom))\n",
    "print(np.shape(fit_gd[2:]))\n",
    "print(np.shape(fit_ld[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 atoms in this sytem, 4 Hf, 8 O\n",
    "\n",
    "For gdd, first row is global energy descriptors, then there are $12*3=36$ (12 atoms, 3 cartesian directions) rows of descriptor derivatives. The first column is atom id/index (ignore id=0, which is global), then the 1122 descriptors ($560*2=1120$ and two 1-body columns)\n",
    "\n",
    "ldd is, as far as I can tell, kind of nonsense. It's aggregating descriptors that should be different (based off of central atom element type), doing this for both global energy and \"global\" descriptor derivatives. The only way I can justify thiss would be due to the equivalence between AB/BA or something, but then no, I think even AA and BB style descriptors get summed together in a single descriptor column which doesn't make sense. \n",
    "\n",
    "ld_atom has, for each atom, the id, type and then the 560 (local) energy descriptors\n",
    "dd_atom has, for each atom, the id, type, and then the $560*12*3=20160$ descriptor derivatives (i.e. with respect to all other atoms, including itself)\n",
    "\n",
    "fit_gd should have the same global energy descriptors as the first column of gdd \n",
    "fit_ld has the $12*560=6720$ local energy descriptors for each atom, all flattened into a single array. Also it's organized in blocks of descriptors, so the first 12 entries are the first descriptor for atom 1, atom 2, etc., then the next 12 entries are the second descriptor for atom 1, atom 2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdd[0][1:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, a couple notes about how these global descriptors are organized. The first descriptor column is just the one-body descriptor, which has the number of Hf atoms in this case (implying that Hf atom is the first type, so type A). Then, starting with the 2-body descriptors, we have the 8 AA descriptors, then the 8 AB descriptors. Then we move to the three body descriptors, etc. \n",
    "\n",
    "Now we skip ahead to descriptors corresponding to a central atom of O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdd[0][562:583]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, once again, the first column corresponds to the 1-body descriptor, then we have 8 BA descriptors, 8 BB, then move on to the 3 body descriptors. \n",
    "\n",
    "Now a key thing to note here is that Cuong has set up POD in such a way that AB and BA are equivalent (this is not necessarily true in other potentials like ACE). Despite this equivalence, here they are explicitly listed out even though they are equivalent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(gdd[0][10:18],gdd[0][563:571],atol=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, this explicit AB/BA enumeration also shows up in the coefficients and in the displayed calculation of the number of global descriptors in the LAMMPS output. Critically, they are very close to each other, but not equivalent! So clearly some numerical noise preventing the exact coefficients from being recovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coeffs[9:17])\n",
    "print(coeffs[562:570])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threebody_invar(p,q,s,Ne):\n",
    "    if s >= q:\n",
    "        l = s + (q-1)*Ne - q*(q-1)/2 + (p-1)*Ne*(1+Ne)/2 \n",
    "    else:\n",
    "        l = q + (s-1)*Ne -s*(s-1)/2 + (p-1)*Ne*(1+Ne)/2 \n",
    "    return int(l)\n",
    "\n",
    "def iterate_3body_invar(Ne): \n",
    "    for p in range(1,Ne+1):\n",
    "        for q in range(1,Ne+1):\n",
    "            for s in range(1,Ne+1):\n",
    "                l = threebody_invar(p,q,s,Ne)\n",
    "                print(f\"{p}{q}{s}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_3body_invar(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is this equivalence, it does **not** show up in the descriptors or coefficients, as can be seen by the following quick check, which demos that the only contiguous stretch of repeated descriptors is with the two-body (other matches are spurious/a consequence of just looking at one small and fairly symmetric configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1122):\n",
    "    for j in range(i,1122):\n",
    "        if i!=j and np.isclose(gdd[0][i+1], gdd[0][j+1], atol=1e-8):\n",
    "            print(f\"{i} {j} {gdd[0][i+1]} {gdd[0][j+1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, the global descriptors printed by the dump and that outputted during fitpod are not the same. (close, but meaningfully different)\n",
    "Nevermind, this was because I was displacing the atoms in the lammps dump test. oops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdd[0][1:10])\n",
    "print(fit_gd[2:12])\n",
    "np.allclose(gdd[0][1:],fit_gd[2:],atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ld_atom[0][2:12])\n",
    "print(fit_ld[2:122:12])\n",
    "\n",
    "np.allclose(ld_atom[0][2:],fit_ld[2:6720:12], atol=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that I can do this as expected with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = np.zeros(12)\n",
    "add_arr1 = np.array([0,2,2,2,2,2,])\n",
    "add_arr2 = np.array([1,10,10,10,10,10])\n",
    "\n",
    "test_arr[1:6] += add_arr1[1:]\n",
    "test_arr[7:]  += add_arr2[1:]\n",
    "print(test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that I can recover the global descriptors from the local descriptors without any funkiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gd = np.zeros(1122)\n",
    "num_ld = 561\n",
    "for atom_ld in ld_atom:\n",
    "    atom_type = int(atom_ld[1]) -1 \n",
    "    my_gd[atom_type*num_ld] += 1.0\n",
    "    start = (atom_type*num_ld)+1\n",
    "    stop = start + num_ld-1\n",
    "    my_gd[start:stop] += atom_ld[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_gd[:10])\n",
    "print(gdd[0][1:11])\n",
    "np.allclose(my_gd, gdd[0][1:], atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_energy = np.loadtxt(\"pe.dat\",skiprows=1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good agreement, though there is likely some issue with the output precision of the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_check = np.dot(coeffs,gdd[0][1:])\n",
    "print(ref_energy)\n",
    "print(energy_check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I thought that using higher precision local descriptors would get a better accuracy, but actually it got a bit worse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_check2 = np.dot(coeffs,my_gd)\n",
    "print(energy_check2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
