{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "\n",
    "using PotentialLearning, InteratomicPotentials\n",
    "using Unitful\n",
    "using Random\n",
    "using AtomsBase\n",
    "using DelimitedFiles\n",
    "using Statistics: mean, var\n",
    "using StatsBase\n",
    "using Clustering, Distances\n",
    "using Trapz\n",
    "using LinearAlgebra: Symmetric, eigen, mul!, svd, cond, dot, norm\n",
    "\n",
    "using MultivariateStats, StatsAPI\n",
    "\n",
    "#using CairoMakie CairoMakie.activate!()\n",
    "using GLMakie; GLMakie.activate!(inline=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ace = ACE(species           = [:C,:H,:O,:N],\n",
    "          body_order        = 3,\n",
    "          polynomial_degree = 10,\n",
    "          wL                = 2.0,\n",
    "          csp               = 1.0,\n",
    "          r0                = 1.43,\n",
    "          rcutoff           = 4.4 )\n",
    "lb = LBasisPotential(ace)\n",
    "length(ace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_file = \"../files/QM9/qm9_fullset_alldata.xyz\"\n",
    "raw_data = load_data(qm9_file, ExtXYZ(u\"eV\", u\"Å\"))\n",
    "raw_data = DataSet([config for config in raw_data if !(:F in atomic_symbol(get_system(config)))])\n",
    "\n",
    "max_num_train = 120_001\n",
    "master_perm_idxs = readdlm(\"./primary_permutation.txt\", Int64)\n",
    "possible_training_idxs = master_perm_idxs[1:max_num_train]\n",
    "possible_test_idxs = master_perm_idxs[max_num_train+1:end]\n",
    "\n",
    "num_train = 40_000\n",
    "train_idxs = possible_training_idxs[1:num_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.β .= readdlm(\"qm9_4elem_3body_poly10_fit40K.txt\", Float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etest_ref = get_all_energies(raw_data[possible_test_idxs])\n",
    "\n",
    "etest_local_descrs = compute_local_descriptors(raw_data[possible_test_idxs],lb.basis)\n",
    "ds_test = DataSet(raw_data[possible_test_idxs] .+ etest_local_descrs)\n",
    "etest_pred = get_all_energies(ds_test,lb)\n",
    "\n",
    "num_atoms_test = length.(get_system.(raw_data[possible_test_idxs]))\n",
    "\n",
    "@show e_mae, e_rmse, e_rsq = calc_metrics(etest_pred,etest_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_mean_features(ds)\n",
    "    mean_feature_perconfig = Vector{Float64}[]\n",
    "    for (i,config) in enumerate(ds)\n",
    "        if i % 100 == 0\n",
    "            println(i)\n",
    "        end\n",
    "        mean_feature = mean(InteratomicPotentials.compute_local_descriptors(get_system(config), lb.basis))\n",
    "        push!(mean_feature_perconfig,mean_feature)\n",
    "    end\n",
    "\n",
    "    reduce(hcat,mean_feature_perconfig)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_features = compute_mean_features(raw_data[train_idxs])\n",
    "mean_test_features  = compute_mean_features(raw_data[possible_test_idxs])\n",
    "\n",
    "dt = StatsBase.fit(ZScoreTransform, mean_train_features, dims=2, scale=false)\n",
    "central_mean_train_features = StatsBase.transform(dt,mean_train_features)\n",
    "central_mean_test_features = StatsBase.transform(dt,mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = StatsAPI.fit(MultivariateStats.PCA, central_mean_train_features; mean=0)\n",
    "\n",
    "pca_central_train_features = StatsAPI.predict(M1, central_mean_train_features)\n",
    "pca_central_test_features = StatsAPI.predict(M1, central_mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pca_central_train_features\n",
    "km_5  = kmeans(train_features, 5, distance=Distances.Euclidean(), rng=Xoshiro(1))\n",
    "km_10 = kmeans(train_features, 10, distance=Distances.Euclidean(), rng=Xoshiro(1))\n",
    "km_20 = kmeans(train_features, 20, distance=Distances.Euclidean(), rng=Xoshiro(1))\n",
    "km_50 = kmeans(train_features, 50, distance=Distances.Euclidean(), rng=Xoshiro(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function normdists2centers(feature_vec, km)\n",
    "    dists = mapslices(x->Distances.euclidean(feature_vec,x), km.centers, dims=1)\n",
    "    normed_dists = dists ./ sum(dists)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist2centers_20 = mapslices(x->reshape(normdists2centers(x,km_20),:,1), pca_central_train_features; dims=1)\n",
    "train_assignments_20 = vec(mapslices(x->argmax(x), train_dist2centers_20; dims=1))\n",
    "num_inclusters_20 = [length(findall(==(i), train_assignments_20)) for i in 1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist2centers_50 = mapslices(x->reshape(normdists2centers(x,km_50),:,1), pca_central_train_features; dims=1)\n",
    "train_assignments_50 = vec(mapslices(x->argmax(x), train_dist2centers_50; dims=1))\n",
    "num_inclusters_50 = [length(findall(==(i), train_assignments_50)) for i in 1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist2centers_10 = mapslices(x->reshape(normdists2centers(x,km_10),:,1), pca_central_train_features; dims=1)\n",
    "train_assignments_10 = vec(mapslices(x->argmax(x), train_dist2centers_10; dims=1))\n",
    "num_inclusters_10 = [length(findall(==(i), train_assignments_10)) for i in 1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist2centers_5 = mapslices(x->reshape(normdists2centers(x,km_5),:,1), pca_central_train_features; dims=1)\n",
    "train_assignments_5 = vec(mapslices(x->argmax(x), train_dist2centers_5; dims=1))\n",
    "num_inclusters_5 = [length(findall(==(i), train_assignments_5)) for i in 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_M = StatsAPI.fit(MultivariateStats.PCA, central_mean_train_features; mean=0, pratio=0.8, maxoutdim=5)\n",
    "alt_pca_central_train_features = StatsAPI.predict(alt_M, central_mean_train_features)\n",
    "alt_pca_central_test_features = StatsAPI.predict(alt_M, central_mean_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_idx = 7\n",
    "alt_train_features = alt_pca_central_train_features\n",
    "alt_km_4  = kmeans(alt_train_features, 4, distance=Distances.Euclidean(), rng=Xoshiro(rng_idx))\n",
    "alt_km_5  = kmeans(alt_train_features, 5, distance=Distances.Euclidean(), rng=Xoshiro(rng_idx))\n",
    "alt_km_10 = kmeans(alt_train_features, 10, distance=Distances.Euclidean(), rng=Xoshiro(rng_idx))\n",
    "alt_km_20 = kmeans(alt_train_features, 20, distance=Distances.Euclidean(), rng=Xoshiro(rng_idx))\n",
    "alt_km_50 = kmeans(alt_train_features, 50, distance=Distances.Euclidean(), rng=Xoshiro(rng_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train_dist2centers_4 = mapslices(x->reshape(normdists2centers(x,alt_km_4),:,1), alt_pca_central_train_features; dims=1)\n",
    "alt_train_assignments_4 = vec(mapslices(x->argmax(x), alt_train_dist2centers_4; dims=1))\n",
    "alt_num_inclusters_4 = [length(findall(==(i), alt_train_assignments_4)) for i in 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train_dist2centers_5 = mapslices(x->reshape(normdists2centers(x,alt_km_5),:,1), alt_pca_central_train_features; dims=1)\n",
    "alt_train_assignments_5 = vec(mapslices(x->argmax(x), alt_train_dist2centers_5; dims=1))\n",
    "alt_num_inclusters_5 = [length(findall(==(i), alt_train_assignments_5)) for i in 1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train_dist2centers_10 = mapslices(x->reshape(normdists2centers(x,alt_km_10),:,1), alt_pca_central_train_features; dims=1)\n",
    "alt_train_assignments_10 = vec(mapslices(x->argmax(x), alt_train_dist2centers_10; dims=1))\n",
    "alt_num_inclusters_10 = [length(findall(==(i), alt_train_assignments_10)) for i in 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So unlike the standardized approach, where with the second PCA I was able to reliably get 4 clusters, here I seem to only be getting two clusters only (and everything else empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_train_dist2centers_50 = mapslices(x->reshape(normdists2centers(x,alt_km_50),:,1), alt_pca_std_train_features; dims=1)\n",
    "alt_train_assignments_50 = vec(mapslices(x->argmax(x), alt_train_dist2centers_50; dims=1))\n",
    "alt_num_inclusters_50 = [length(findall(==(i), alt_train_assignments_50)) for i in 1:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(stdout, \"text/plain\", alt_num_inclusters_50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
